{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e041be-f8ce-4036-a9fa-5be081b3538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation \n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "#MAchine learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79e17618-97b6-4199-b9b2-e3701a6bb053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: hyperopt\n",
      "Version: 0.2.7\n",
      "Summary: Distributed Asynchronous Hyperparameter Optimization\n",
      "Home-page: https://hyperopt.github.io/hyperopt\n",
      "Author: James Bergstra\n",
      "Author-email: james.bergstra@gmail.com\n",
      "License: BSD\n",
      "Location: c:\\users\\ena\\anaconda3\\lib\\site-packages\n",
      "Requires: cloudpickle, future, networkx, numpy, py4j, scipy, six, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c74a60-19b6-4e73-b89d-a509f82789ba",
   "metadata": {},
   "source": [
    "# Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88a835-4dfd-49b2-b54b-89e70db7feb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"C:/Users/Ena/Desktop/THESIS/eyetzip_data_with_score.csv\", low_memory=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c38a5-5fb9-4fd9-9e73-a7c20dfbd8e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2b31d-631c-49bc-935c-0b111bc7964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data based on project name\n",
    "control_group_data = df2[df2['Project name'] == 'Control group experiment']\n",
    "test_group_data = df2[df2['Project name'] == 'Test group experiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa1991-1fe4-46ea-8f7d-9e2dbd8180a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from PRIYANK RAVAL's Kaggle notebook: https://www.kaggle.com/code/priyankraval/eyet-empathyscore-ipynb#Step-3-:-#Load-eyetzip_data_with_score.csv-with-empathy-score-for-data-analysis\n",
    "# Select relevant columns for control group\n",
    "control_selected_columns = ['Participant name', 'Recording duration',\n",
    "                             'Pupil diameter left', 'Pupil diameter right',\n",
    "                             'Eye position left X (DACSmm)', 'Eye position left Y (DACSmm)', 'Eye position left Z (DACSmm)',\n",
    "                             'Eye position right X (DACSmm)', 'Eye position right Y (DACSmm)', 'Eye position right Z (DACSmm)',\n",
    "                             'Gaze event duration', 'Fixation point X', 'Fixation point Y', 'Total Score extended', 'Gaze point X', 'Gaze point Y', 'Gaze event duration']\n",
    "\n",
    "# Create a DataFrame with selected columns for control group\n",
    "control_group_selected = control_group_data[control_selected_columns]\n",
    "\n",
    "# Select relevant columns for test group\n",
    "test_selected_columns = ['Participant name', 'Recording duration',\n",
    "                         'Pupil diameter left', 'Pupil diameter right',\n",
    "                         'Eye position left X (DACSmm)', 'Eye position left Y (DACSmm)', 'Eye position left Z (DACSmm)',\n",
    "                         'Eye position right X (DACSmm)', 'Eye position right Y (DACSmm)', 'Eye position right Z (DACSmm)',\n",
    "                         'Gaze event duration', 'Fixation point X', 'Fixation point Y', 'Total Score extended', 'Gaze point X', 'Gaze point Y', 'Gaze event duration']\n",
    "\n",
    "# Create a DataFrame with selected columns for test group\n",
    "test_group_selected = test_group_data[test_selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25568d3c-f62b-4983-b4f6-e760eb535435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "not_in_list = sorted(set(df2.columns) - set(control_selected_columns))\n",
    "\n",
    "print(\"Columns not in the given list:\", list(not_in_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3f3cd-f3ed-42e5-8199-776bddca2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(control_group_selected.columns))\n",
    "print(sorted(test_group_selected.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d99906-2674-4948-82ab-a1150bcd3a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with 0 in control group dataframe\n",
    "control_group_selected = control_group_selected.fillna(0)\n",
    "\n",
    "# Replace NaN values with 0 in test group dataframe\n",
    "test_group_selected = test_group_selected.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc181fd7-1074-48a1-a1eb-22bafe81b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from PRIYANK RAVAL's Kaggle notebook: https://www.kaggle.com/code/priyankraval/eyet-empathyscore-ipynb#Step-3-:-#Load-eyetzip_data_with_score.csv-with-empathy-score-for-data-analysis\n",
    "# Create copies of the DataFrames to avoid the SettingWithCopyWarning\n",
    "control_group_selected = control_group_selected.copy()\n",
    "test_group_selected = test_group_selected.copy()\n",
    "\n",
    "# Calculate Eye_Position_Ratio_X\n",
    "control_group_selected['Eye_Position_Ratio_X'] = control_group_selected['Eye position left X (DACSmm)'] / (control_group_selected['Eye position right X (DACSmm)'] + 1e-6)\n",
    "test_group_selected['Eye_Position_Ratio_X'] = test_group_selected['Eye position left X (DACSmm)'] / (test_group_selected['Eye position right X (DACSmm)'] + 1e-6)\n",
    "\n",
    "# Calculate Eye_Position_Ratio_Y\n",
    "control_group_selected['Eye_Position_Ratio_Y'] = control_group_selected['Eye position left Y (DACSmm)'] / (control_group_selected['Eye position right Y (DACSmm)'] + 1e-6)\n",
    "test_group_selected['Eye_Position_Ratio_Y'] = test_group_selected['Eye position left Y (DACSmm)'] / (test_group_selected['Eye position right Y (DACSmm)'] + 1e-6)\n",
    "\n",
    "# Calculate Eye_Position_Ratio_Z\n",
    "control_group_selected['Eye_Position_Ratio_Z'] = control_group_selected['Eye position left Z (DACSmm)'] / (control_group_selected['Eye position right Z (DACSmm)'] + 1e-6)\n",
    "test_group_selected['Eye_Position_Ratio_Z'] = test_group_selected['Eye position left Z (DACSmm)'] / (test_group_selected['Eye position right Z (DACSmm)'] + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1840bb-b9da-4627-ae8b-8ac7756b93e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns used in feature engineering\n",
    "columns_to_drop = ['Eye position left X (DACSmm)', 'Eye position right X (DACSmm)',\n",
    "                   'Eye position left Y (DACSmm)', 'Eye position right Y (DACSmm)',\n",
    "                   'Eye position left Z (DACSmm)', 'Eye position right Z (DACSmm)',\n",
    "                   'Gaze point left Y', 'Gaze point right X', 'Gaze point right Y',\n",
    "                   ]\n",
    "\n",
    "control_group_selected.drop(columns=columns_to_drop, inplace=True)\n",
    "test_group_selected.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f59b8c-1e3e-4213-be65-c439b70259ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from PRIYANK RAVAL's Kaggle notebook: https://www.kaggle.com/code/priyankraval/eyet-empathyscore-ipynb#Step-3-:-#Load-eyetzip_data_with_score.csv-with-empathy-score-for-data-analysis\n",
    "# Define the input features (X) and target variable (y) for control group\n",
    "X_control_group = control_group_selected.drop(columns=['Total Score extended', 'Participant name', 'Recording duration', 'Pupil diameter left', 'Pupil diameter right'])\n",
    "y_control_group = control_group_selected['Total Score extended']\n",
    "\n",
    "\n",
    "# Define the input features (X) and target variable (y) for test group\n",
    "X_t_group= test_group_selected.drop(columns=['Total Score extended', 'Participant name', 'Recording duration', 'Pupil diameter left', 'Pupil diameter right'])\n",
    "y_t_group = test_group_selected['Total Score extended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da55a8-bf10-4eae-9aa2-ce977f3f301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_t_group.columns)\n",
    "print(X_control_group.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a650f-eb3a-415e-9383-3c2edb2dd820",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.80\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "X_control_train, X_control_test, y_control_train, y_control_test = train_test_split(X_control_group, y_control_group, test_size=1 - train_ratio)\n",
    "\n",
    "\n",
    "x_control_val, x_control_test, y_control_val, y_control_test = train_test_split(X_control_test, y_control_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "print(X_control_train.shape, x_control_val.shape, x_control_test.shape)\n",
    "print(y_control_train.shape, y_control_val.shape, y_control_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "train_ratio = 0.80\n",
    "validation_ratio = 0.10\n",
    "test_ratio = 0.10\n",
    "\n",
    "X_t_train, X_t_test, y_t_train, y_t_test = train_test_split(X_t_group, y_t_group, test_size=1 - train_ratio)\n",
    "\n",
    "x_t_val, x_t_test, y_t_val, y_t_test = train_test_split(X_t_test, y_t_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "print(X_t_train.shape, x_t_val.shape, x_t_test.shape)\n",
    "print(y_t_train.shape, y_t_val.shape, y_t_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a6a88-a4f1-4823-a613-ac07d9174a45",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb691d4-7723-420d-bdc4-1b5f4eb7385a",
   "metadata": {},
   "source": [
    "### Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b58b7-4cdc-4bed-a349-a69eac280dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "linear_model_control = LinearRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "linear_model_control.fit(X_control_train, y_control_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_control_pred = linear_model_control.predict(x_control_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_control_test, y_control_pred)\n",
    "r2 = r2_score(y_control_test, y_control_pred)  \n",
    "mae = mean_absolute_error(y_control_test, y_control_pred)\n",
    "print(\"control group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d016515-0c7b-4821-976b-d6c3e7779d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = abs(linear_model_control.coef_)\n",
    "feature_names = X_control_train.columns.tolist() \n",
    "# Iterate over both lists simultaneously\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "    # Format the output to display feature name and coefficient magnitude rounded to 3 decimals\n",
    "    print(f'{name}: {importance:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b81cd-c8ec-425b-80b4-5e2d89ee7ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Coefficient Magnitude')\n",
    "plt.title('Linear Regression Feature Importance Control Group without Pupil dilation')\n",
    "plt.savefig(\"lr_FI_control_wp.jpg\", bbox_inches='tight' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aa0c6-640c-43fd-9f07-a470cd00098f",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07be04-24b1-418a-b9fd-692ff7f1b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression model\n",
    "linear_model_test = LinearRegression()\n",
    "\n",
    "# Train the model on the training set\n",
    "linear_model_test.fit(X_t_train, y_t_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = linear_model_test.predict(x_t_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_t_test, y_pred)\n",
    "r2 = r2_score(y_t_test, y_pred)  \n",
    "mae = mean_absolute_error(y_t_test, y_pred)\n",
    "print(\"test group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b89bc-6b9f-4a0c-93eb-b85d26f2408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = abs(linear_model_test.coef_)\n",
    "feature_names = X_t_train.columns.tolist() \n",
    "# Iterate over both lists simultaneously\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "    # Format the output to display feature name and coefficient magnitude rounded to 3 decimals\n",
    "    print(f'{name}: {importance:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ec307-a8d1-4840-8dbf-6f4c49aea5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Coefficient Magnitude')\n",
    "plt.title('Linear Regression Feature Importance Control Group without Pupil dilation')\n",
    "plt.savefig(\"lr_FI_test_wp.jpg\", bbox_inches='tight' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf2659-e4a0-4921-ada0-18038293edb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from PRIYANK RAVAL's Kaggle notebook: https://www.kaggle.com/code/priyankraval/eyet-empathyscore-ipynb#Step-3-:-#Load-eyetzip_data_with_score.csv-with-empathy-score-for-data-analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual vs predicted for the treatment group\n",
    "plt.scatter(y_t_test, y_pred, color='blue', label='Test Predictions')\n",
    "plt.scatter(y_t_test, y_t_test, color=\"red\", label='Test Actual')\n",
    "\n",
    "# Plot actual vs predicted for the control group\n",
    "plt.scatter(y_control_test, y_control_pred, color='purple', label='Control Predictions')\n",
    "plt.scatter(y_control_test, y_control_test, color=\"green\", label='Control Actual')\n",
    "\n",
    "plt.plot([min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         [min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted Linear Regression without pupil dilation')\n",
    "plt.legend()\n",
    "plt.savefig(\"score_best_lr_WP.jpg\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a7010-8330-4ca8-b509-5e301711346e",
   "metadata": {},
   "source": [
    "# Decision Tree regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a829a-14d0-45bd-8096-1cb11f0edbac",
   "metadata": {},
   "source": [
    "### base model & tunning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884095d5-92d6-4ae9-8cb4-65142d15e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model_control = DecisionTreeRegressor(max_depth=3, random_state=42).fit(X_control_train, y_control_train) # You can adjust max_depth\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_control_pred = dt_model_control.predict(x_control_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_control_test, y_control_pred)\n",
    "r2 = r2_score(y_control_test, y_control_pred)  \n",
    "mae = mean_absolute_error(y_control_test, y_control_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "\n",
    "dt_model_test = DecisionTreeRegressor(max_depth=3, random_state=42) # You can adjust max_depth\n",
    "dt_model_test.fit(X_t_train, y_t_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = dt_model_test.predict(x_t_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_t_test, y_pred)\n",
    "r2 = r2_score(y_t_test, y_pred)  \n",
    "mae = mean_absolute_error(y_t_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aae356-b221-4bad-b721-94f0223b9d2a",
   "metadata": {},
   "source": [
    "### Tuning control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e6279-1186-4c54-bdb2-8d8a35142bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Objective Function\n",
    "def objective(params):\n",
    "    dt = DecisionTreeRegressor(**params, random_state=42)\n",
    "    dt.fit(X_control_train, y_control_train)  # Train the model on the validation set\n",
    "    y_pred = dt.predict(x_control_val)\n",
    "    mse = mean_squared_error(y_control_val, y_pred)\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define Search Space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1, 11)),  # Vary max_depth from 1 to 10\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 11)),  # Vary min_samples_split from 2 to 10\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 11)),  # Vary min_samples_leaf from 1 to 10\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None])  # Vary max_feature\n",
    "}\n",
    "\n",
    "# Run Hyperparameter Optimization\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters control group :\", best)\n",
    "#Best hyperparameters control group : {'max_depth': 8, 'max_features': 2, 'min_samples_leaf': 7, 'min_samples_split': 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2f181-38f0-4a01-9432-524545e0f124",
   "metadata": {},
   "source": [
    "### Tuning Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae06f99-e7ae-4b80-a842-4e100e43887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    dt = DecisionTreeRegressor(**params, random_state=42)\n",
    "    dt.fit(X_t_train, y_t_train)  # Train the model on the validation set\n",
    "    y_pred = dt.predict(x_t_val)\n",
    "    mse = mean_squared_error(y_t_val, y_pred)\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define Search Space\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(1, 11)),  # Vary max_depth from 1 to 10\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 11)),  # Vary min_samples_split from 2 to 10\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 11)),  # Vary min_samples_leaf from 1 to 10\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None])  # Vary max_features\n",
    "}\n",
    "\n",
    "# Run Hyperparameter Optimization\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters test group :\", best)\n",
    "#Best hyperparameters test group : {'max_depth': 9, 'max_features': 2, 'min_samples_leaf': 9, 'min_samples_split': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e3e34-85cc-4eb4-a536-95f2db05cb66",
   "metadata": {},
   "source": [
    "### Best model control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616f2c4-e824-464d-9995-823c321c9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_control_dt = DecisionTreeRegressor(max_depth = 8, max_features= None, min_samples_leaf= 7, min_samples_split= 5, random_state=42).fit(X_control_train, y_control_train) \n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_control_pred = best_control_dt.predict(x_control_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_control_test, y_control_pred)\n",
    "r2 = r2_score(y_control_test, y_control_pred)  \n",
    "mae = mean_absolute_error(y_control_test, y_control_pred)\n",
    "print(\"control group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e5da3-4176-4123-9f5e-142f7069b24e",
   "metadata": {},
   "source": [
    "#### feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36ab5f-b73b-4a62-a099-e994daa606d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = best_control_dt.feature_importances_\n",
    "feature_names = X_control_train.columns.tolist()\n",
    "\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "\n",
    "    print(f'{name}: {importance:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e265da0-17b8-4742-82db-319d334f45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Decision Tree RegressorFeature Importance Control Group without pupil dilation')\n",
    "plt.savefig(\"dt_FI_control_wp.jpg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63a2ca-e8e9-47df-9600-4312f080f3d6",
   "metadata": {},
   "source": [
    "### Best model Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ae97a-aa63-4587-977c-3fa321d8a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_t_dt = DecisionTreeRegressor(max_depth = 9, max_features= None, min_samples_leaf= 9 ,min_samples_split= 4, random_state=42).fit(X_t_train, y_t_train) \n",
    "# Make predictions on the testing set\n",
    "y_pred = best_t_dt.predict(x_t_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_t_test, y_pred)\n",
    "r2 = r2_score(y_t_test, y_pred)  \n",
    "mae = mean_absolute_error(y_t_test, y_pred)\n",
    "print(\"test group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317deb8c-ecad-4d9f-bf4a-359ae313360d",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdeebb6-70dd-4a61-82d1-a5dfeed45890",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = best_t_dt.feature_importances_\n",
    "feature_names = X_t_train.columns.tolist()\n",
    "\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "\n",
    "    print(f'{name}: {importance:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79585c5-79aa-4fb5-ab05-92c840303d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Decision Tree RegressorFeature Importance Test Group without pupil dilation')\n",
    "plt.savefig(\"dt_FI_test_wp.jpg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9b3b6-e330-492c-a08f-6a0beed2f05e",
   "metadata": {},
   "source": [
    "#### visual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b0607-9ebc-4bda-9d60-b9db13fab5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from PRIYANK RAVAL's Kaggle notebook: https://www.kaggle.com/code/priyankraval/eyet-empathyscore-ipynb#Step-3-:-#Load-eyetzip_data_with_score.csv-with-empathy-score-for-data-analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual vs predicted for the treatment group\n",
    "plt.scatter(y_t_test, y_pred, color='blue', label='Test Predictions')\n",
    "plt.scatter(y_t_test, y_t_test, color=\"red\", label='Test Actual')\n",
    "\n",
    "# Plot actual vs predicted for the control group\n",
    "plt.scatter(y_control_test, y_control_pred, color='purple', label='Control Predictions')\n",
    "plt.scatter(y_control_test, y_control_test, color=\"green\", label='Control Actual')\n",
    "\n",
    "plt.plot([min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         [min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted Decision Tree Regressor without pupil dilation')\n",
    "plt.legend()\n",
    "plt.savefig(\"score_best_dt_WP.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca413fc-7a5e-453d-ad11-81937cc11b2f",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f15e4-6f6e-4a77-822d-5f56e4751e28",
   "metadata": {},
   "source": [
    "#### base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170013df-c30e-47bf-95b0-5e0820d2a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_control = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Training and evaluation for Gradient Boosting Regressor\n",
    "print(\"Gradient Boosting Regressor - Control Group:\")\n",
    "gb_model_control.fit(X_control_train, y_control_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_control_pred = gb_model_control.predict(x_control_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_control_test, y_control_pred)\n",
    "r2 = r2_score(y_control_test, y_control_pred)  \n",
    "mae = mean_absolute_error(y_control_test, y_control_pred)\n",
    "print(\"control group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))\n",
    "\n",
    "\n",
    "gb_model_test = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Training and evaluation for Gradient Boosting Regressor\n",
    "print(\"Gradient Boosting Regressor - test Group:\")\n",
    "gb_model_test= gb_model_test.fit(X_t_train, y_t_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = gb_model_test.predict(x_t_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_t_test, y_pred)\n",
    "r2 = r2_score(y_t_test, y_pred)  \n",
    "mae = mean_absolute_error(y_t_test, y_pred)\n",
    "print(\"test group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2adaad-5d73-4a6a-91fe-51916447fa5b",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37723f-8f59-49ac-a52a-10ff417ab469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Objective Function\n",
    "def objective(params):\n",
    "    gb = GradientBoostingRegressor(**params, random_state=42)\n",
    "    gb.fit(X_control_train, y_control_train)  # Train the model on the validation set\n",
    "    y_pred = gb.predict(x_control_val)\n",
    "    mse = mean_squared_error(y_control_val, y_pred)\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define Search Space\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 201, 20)),  # Vary number of trees from 50 to 200\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),  # Vary learning rate exponentially\n",
    "    'max_depth': hp.choice('max_depth', range(1, 11)),  # Vary max_depth from 1 to 10\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 11)),  # Vary min_samples_split from 2 to 10\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 11)),  # Vary min_samples_leaf from 1 to 10\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None])  # Vary max_features\n",
    "}\n",
    "# Run Hyperparameter Optimization\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters control group :\", best)\n",
    "#Best hyperparameters control group : {'learning_rate': 0.1930943989046583, 'max_depth': 8, 'max_features': 1, 'min_samples_leaf': 0, 'min_samples_split': 2, 'n_estimators': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a27e3a-783b-40f9-9acf-f33609adfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    gbt = GradientBoostingRegressor(**params, random_state=42)\n",
    "    gbt.fit(X_t_train, y_t_train)  # Train the model on the validation set\n",
    "    y_pred = gbt.predict(x_t_val)\n",
    "    mse = mean_squared_error(y_t_val, y_pred)\n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define Search Space\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 201, 20)),  # Vary number of trees from 50 to 200\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),  # Vary learning rate exponentially\n",
    "    'max_depth': hp.choice('max_depth', range(1, 11)),  # Vary max_depth from 1 to 10\n",
    "    'min_samples_split': hp.choice('min_samples_split', range(2, 11)),  # Vary min_samples_split from 2 to 10\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', range(1, 11)),  # Vary min_samples_leaf from 1 to 10\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None])  # Vary max_features\n",
    "}\n",
    "# Run Hyperparameter Optimization\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters test group :\", best)\n",
    "#Best hyperparameters test group : {'learning_rate': 0.38566707194790334, 'max_depth': 9, 'max_features': 2, 'min_samples_leaf': 3, 'min_samples_split': 0, 'n_estimators': 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401515f-28b9-43b1-863e-df9c9ce53192",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec832a5b-279a-41c6-8c03-1f558ef8c0ba",
   "metadata": {},
   "source": [
    "#### Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009835c-e5f4-4e7a-8a80-ea337cc0ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_control = GradientBoostingRegressor(learning_rate= 0.3256474619914467, max_depth= 9, max_features = 'log2', min_samples_leaf = 9, min_samples_split = 6, n_estimators= 90, random_state=42)\n",
    "\n",
    "# Training and evaluation for Gradient Boosting Regressor\n",
    "print(\"Gradient Boosting Regressor - Control Group:\")\n",
    "gb_model_control.fit(X_control_train, y_control_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_control_pred = gb_model_control.predict(x_control_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_control_test, y_control_pred)\n",
    "r2 = r2_score(y_control_test, y_control_pred)  \n",
    "mae = mean_absolute_error(y_control_test, y_control_pred)\n",
    "print(\"control group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c56e8e-5dc8-4312-a1ac-66d14ee385fd",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913df27-c6a4-4824-8057-7aaa0e9dabdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = gb_model_control.feature_importances_\n",
    "feature_names = X_control_train.columns.tolist()\n",
    "\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "\n",
    "    print(f'{name}: {importance:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44f613-8793-49aa-98a2-26c9da5277cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Gradient Boosting Regressor Feature Importance for control group without pupil dilation ')\n",
    "plt.savefig(\"gb_FI_control_wp.jpg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe1bdb4-1889-4cd9-831d-f60821534d50",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f78d91-1288-41ee-a52e-396714079140",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model_test = GradientBoostingRegressor(learning_rate=0.38566707194790334, max_depth= 9, max_features = None , min_samples_leaf = 3, min_samples_split = 2 , n_estimators= 110, random_state=42)\n",
    "\n",
    "# Training and evaluation for Gradient Boosting Regressor\n",
    "print(\"Gradient Boosting Regressor - test Group:\")\n",
    "gb_model_test= gb_model_test.fit(X_t_train, y_t_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = gb_model_test.predict(x_t_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_t_test, y_pred)\n",
    "r2 = r2_score(y_t_test, y_pred)  \n",
    "mae = mean_absolute_error(y_t_test, y_pred)\n",
    "print(\"test group\")\n",
    "print(\"Mean Squared Error: {:.3f}\".format(mse))\n",
    "print(\"R-squared: {:.3f}\".format(r2))\n",
    "print(\"Mean Absolute Error: {:.3f}\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaee84f-8069-4733-ab65-4156fe6a0083",
   "metadata": {},
   "source": [
    "#### feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa70c7b-27e0-4a7f-97b7-cfc374d71170",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = gb_model_test.feature_importances_\n",
    "feature_names = X_t_train.columns.tolist()\n",
    "\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "\n",
    "    print(f'{name}: {importance:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941548fb-07c7-41ce-a093-1fbed4e086ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Gradient Boosting Regressor Feature Importance Test Group without pupil dilation ')\n",
    "plt.savefig(\"gb_FI_test_wp.jpg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361ebea-cf2d-4c8c-bc7b-0050770a4e4f",
   "metadata": {},
   "source": [
    "### Visual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cff257-224b-46ac-acce-ac8289fcb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from PRIYANK RAVAL's Kaggle notebook: https://www.kaggle.com/code/priyankraval/eyet-empathyscore-ipynb#Step-3-:-#Load-eyetzip_data_with_score.csv-with-empathy-score-for-data-analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual vs predicted for the treatment group\n",
    "plt.scatter(y_t_test, y_pred, color='blue', label='Test Predictions')\n",
    "plt.scatter(y_t_test, y_t_test, color=\"red\", label='Test Actual')\n",
    "\n",
    "# Plot actual vs predicted for the control group\n",
    "plt.scatter(y_control_test, y_control_pred, color='purple', label='Control Predictions')\n",
    "plt.scatter(y_control_test, y_control_test, color=\"green\", label='Control Actual')\n",
    "\n",
    "plt.plot([min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         [min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.savefig(\"score_best_gb_WP.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aca4dd-603e-4b82-8079-76e261bd219b",
   "metadata": {},
   "source": [
    "## ADA BOOSTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be85f7a-99c3-469a-af8d-d66c3175ef93",
   "metadata": {},
   "source": [
    "### base model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1db2c2-23d5-46c6-b714-5d9e8f70cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_model_control = AdaBoostRegressor(n_estimators=50, random_state=42).fit(X_control_train, y_control_train) \n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_control_pred = ab_model_control.predict(x_control_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_control_test, y_control_pred)\n",
    "r2 = r2_score(y_control_test, y_control_pred)  \n",
    "mae = mean_absolute_error(y_control_test, y_control_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "\n",
    "ab_model_test = AdaBoostRegressor(n_estimators=50, random_state=42) \n",
    "ab_model_test.fit(X_t_train, y_t_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = dt_model_test.predict(x_t_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_t_test, y_pred)\n",
    "r2 = r2_score(y_t_test, y_pred)  \n",
    "mae = mean_absolute_error(y_t_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f48ca60-5303-4d6f-8e2f-a975a30101c1",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774bc4f-c7fc-4219-8bef-a6a8193c9bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Objective Function\n",
    "def objective(params):\n",
    "      # Initialize AdaBoost regressor with the remaining parameters\n",
    "    ab_control = AdaBoostRegressor( **params, random_state=42)\n",
    "    \n",
    "    # Train the model on the validation set\n",
    "    ab_control.fit(X_control_train, y_control_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = ab_control.predict(x_control_val)\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_control_val, y_pred)\n",
    "    \n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define Search Space\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 500, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -4, 0),\n",
    "    'loss': hp.choice('loss', ['linear', 'square', 'exponential']),\n",
    "    'estimator': hp.choice('estimator', [None, DecisionTreeRegressor(max_depth=5),best_control_dt])\n",
    "}\n",
    "\n",
    "\n",
    "# Run Hyperparameter Optimization\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters control group :\", best)\n",
    "#Best hyperparameters control group : {'estimator': 2, 'learning_rate': 0.0368989361218225, 'loss': 0, 'n_estimators': 233}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db176b39-e015-4849-9020-28ca3addeb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Objective Function\n",
    "def objective(params):\n",
    "      # Initialize AdaBoost regressor with the remaining parameters\n",
    "    ab_t = AdaBoostRegressor( **params, random_state=42)\n",
    "    \n",
    "    # Train the model on the validation set\n",
    "    ab_t.fit(X_t_train, y_t_train)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_pred = ab_t.predict(x_t_val)\n",
    "    \n",
    "    # Calculate mean squared error\n",
    "    mse = mean_squared_error(y_t_val, y_pred)\n",
    "    \n",
    "    return {'loss': mse, 'status': STATUS_OK}\n",
    "\n",
    "# Define Search Space\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', range(50, 500, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -4, 0),\n",
    "    'loss': hp.choice('loss', ['linear', 'square', 'exponential']),\n",
    "    'estimator': hp.choice('estimator', [None, DecisionTreeRegressor(max_depth=5),best_t_dt])\n",
    "}\n",
    "\n",
    "\n",
    "# Run Hyperparameter Optimization\n",
    "trials = Trials()\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=20, trials=trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters test group :\", best)\n",
    "#Best hyperparameters test group : {'estimator': 2, 'learning_rate': 0.02848590919273431, 'loss': 2, 'n_estimators': 61}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581da8c-7109-4706-bccd-ad4d00d1437d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Best models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e697f-fb80-4f11-8eb9-66923ffe09ed",
   "metadata": {},
   "source": [
    "#### control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7757a5b-0e85-4eb6-bc8e-b641749429d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_model_control = AdaBoostRegressor(estimator = best_control_dt, learning_rate = 0.0368989361218225, n_estimators=233, loss='linear',  random_state=42).fit(X_control_train, y_control_train) \n",
    "\n",
    "#Best hyperparameters control group : {'estimator': 2, 'learning_rate': 0.0368989361218225, 'loss': 0, 'n_estimators': 233}\n",
    "# Make predictions on the testing set\n",
    "y_control_pred = ab_model_control.predict(x_control_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_control_test, y_control_pred)\n",
    "r2 = r2_score(y_control_test, y_control_pred)  \n",
    "mae = mean_absolute_error(y_control_test, y_control_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72b99f-67b4-469b-83b3-10ea9a71ee7b",
   "metadata": {},
   "source": [
    "#### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def4a7b-5079-4a9a-8f62-65c1bebef618",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = ab_model_control.feature_importances_\n",
    "feature_names = X_control_train.columns.tolist()\n",
    "\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "\n",
    "    print(f'{name}: {importance:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d05ca-e4e8-4b33-8122-5783906bd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('ADA Boosting Regressor Feature Importance for control group without pupil dilation ')\n",
    "plt.savefig(\"ab_FI_control_wp.jpg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42e08d-846f-4356-8d52-f6c37edddaa3",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ae37a-2645-411d-a8b0-8ce64cf27156",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_model_test = AdaBoostRegressor(estimator= best_t_dt, learning_rate =0.02848590919273431, loss = 'exponential', n_estimators=61,  random_state=42) \n",
    "ab_model_test.fit(X_t_train, y_t_train)\n",
    "#Best hyperparameters test group : {'estimator': 2, 'learning_rate': 0.02848590919273431, 'loss': 2, 'n_estimators': 61}\n",
    "# Make predictions on the testing set\n",
    "y_pred = ab_model_test.predict(x_t_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_t_test, y_pred)\n",
    "r2 = r2_score(y_t_test, y_pred)  \n",
    "mae = mean_absolute_error(y_t_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bd6d1-6ed9-4ddd-b998-4a7889abe039",
   "metadata": {},
   "source": [
    "#### feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ce1e8-8577-4884-9ec6-b8a970a817e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = ab_model_test.feature_importances_\n",
    "feature_names = X_t_train.columns.tolist()\n",
    "\n",
    "for name, importance in zip(feature_names, feature_importance):\n",
    "\n",
    "    print(f'{name}: {importance:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af5d1f-55a6-4361-8540-cdb4caa362f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('ADA Boosting Regressor Feature Importance Test Group without pupil dilation ')\n",
    "plt.savefig(\"ab_FI_test_wp.jpg\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f1510-c69c-42c9-8408-f7a3648bfc8d",
   "metadata": {},
   "source": [
    "### Visual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78a30dd-1d87-4865-99c3-a98ebbf53d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function was adapted from PRIYANK RAVAL's Kaggle notebook: https://www.kaggle.com/code/priyankraval/eyet-empathyscore-ipynb#Step-3-:-#Load-eyetzip_data_with_score.csv-with-empathy-score-for-data-analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot actual vs predicted for the treatment group\n",
    "plt.scatter(y_t_test, y_pred, color='blue', label='Test Predictions')\n",
    "plt.scatter(y_t_test, y_t_test, color=\"red\", label='Test Actual')\n",
    "\n",
    "# Plot actual vs predicted for the control group\n",
    "plt.scatter(y_control_test, y_control_pred, color='purple', label='Control Predictions')\n",
    "plt.scatter(y_control_test, y_control_test, color=\"green\", label='Control Actual')\n",
    "\n",
    "plt.plot([min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         [min(y_t_test.min(), y_control_test.min()), max(y_t_test.max(), y_control_test.max())], \n",
    "         color='black', linestyle='--')\n",
    "\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted of ADA Boosting Regressor without pupil dilation')\n",
    "plt.legend()\n",
    "plt.savefig(\"score_best_ab_WP.jpg\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab73109f-bcb2-48f0-8c5a-f669661d5941",
   "metadata": {},
   "source": [
    "# references\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328fa896-8b0d-446c-9a5e-344abb9ff332",
   "metadata": {},
   "source": [
    "Raval, P. (2024). Eyetempathyscore.ipynb. Retrieved 11/01/2024,\n",
    "from http://web.archive.org/web/20080207010024/http://\n",
    "www.808multimedia.com/winnt/kernel.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
